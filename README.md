# üå≥ Comparaci√≥n de √Årboles de Decisi√≥n y Random Forest en la Clasificaci√≥n del Dataset Wine

**Autora:** Christell Lissette Garc√≠a Sagastume  
**Universidad del Valle de Guatemala**

---

## üìë Resumen
Este art√≠culo presenta la comparaci√≥n entre modelos de √Årbol de Decisi√≥n y Random Forest aplicados al *Wine Dataset* disponible en `scikit-learn`.  
Se evaluaron hiperpar√°metros clave como la profundidad m√°xima, el tama√±o m√≠nimo de divisi√≥n y el n√∫mero de estimadores.  

Los resultados muestran que el Random Forest ofrece mayor robustez y estabilidad frente al sobreajuste, logrando un desempe√±o perfecto en el conjunto de prueba, mientras que los √°rboles individuales tienden a sobreajustar. Adem√°s, se analiz√≥ la importancia de las variables, destacando el rol de los flavonoides y el grado alcoh√≥lico en la clasificaci√≥n de los vinos.

---

## üîé Introducci√≥n
Los algoritmos basados en √°rboles son ampliamente utilizados en aprendizaje autom√°tico supervisado debido a su interpretabilidad y simplicidad.  
Sin embargo, los √Årboles de Decisi√≥n pueden sufrir de sobreajuste. Los m√©todos de ensamble, como los Random Forest, reducen esta limitaci√≥n al combinar m√∫ltiples √°rboles, mejorando la capacidad de generalizaci√≥n.

Este estudio compara ambos enfoques aplicados al problema de clasificaci√≥n multiclase del *Wine Dataset* (178 observaciones, 13 atributos qu√≠micos).

---

## ‚öôÔ∏è Metodolog√≠a
1. **Preparaci√≥n de datos:**  
   - Dataset cargado desde `scikit-learn` con `as_frame=True`.  
   - Separaci√≥n en entrenamiento (70%) y prueba (30%), con estratificaci√≥n.  

2. **Modelos entrenados:**  
   - √Årbol de Decisi√≥n b√°sico (hiperpar√°metros por defecto).  
   - √Årbol de Decisi√≥n ajustado (`max_depth=3`, `min_samples_split=10`).  
   - Random Forest b√°sico (hiperpar√°metros por defecto).  
   - Random Forest variando `n_estimators` (10, 50, 200, 500).  

3. **M√©tricas de evaluaci√≥n:**  
   - Accuracy  
   - Matrices de confusi√≥n  
   - Reportes de clasificaci√≥n  
   - Importancia de caracter√≠sticas  

---

## üìä Resultados

- **√Årbol de Decisi√≥n b√°sico:** `Acc_train=1.00`, `Acc_test=0.963` ‚Üí sobreajuste leve.  
- **√Årbol ajustado:** `Acc_train=0.992`, `Acc_test=0.963` ‚Üí ligera mejora en generalizaci√≥n.  
- **Random Forest b√°sico:** `Acc_train=1.00`, `Acc_test=1.00` ‚Üí mayor estabilidad.  
- **Random Forest con m√∫ltiples estimadores:** el desempe√±o se estabiliz√≥ a partir de 50 √°rboles.  
- **Importancia de variables:** flavonoides, alcohol e intensidad de color fueron las m√°s relevantes.  

### Figuras

#### √Årbol de Decisi√≥n b√°sico
![Matriz de confusi√≥n - √Årbol de Decisi√≥n b√°sico](dt_base_confusion_matrix.png)

#### √Årbol de Decisi√≥n ajustado
![Matriz de confusi√≥n - √Årbol de Decisi√≥n ajustado](dt_tuned_confusion_matrix.png)

#### Random Forest b√°sico
![Matriz de confusi√≥n - Random Forest b√°sico](rf_base_confusion_matrix.png)

#### Sweep de n_estimators
![Precisi√≥n vs n√∫mero de √°rboles en Random Forest](rf_n_estimators_sweep.png)

#### Importancia de caracter√≠sticas
![Importancia de caracter√≠sticas en Random Forest](rf_feature_importances.png)

---

## üí¨ Discusi√≥n
- Los √Årboles de Decisi√≥n, aunque interpretables, son propensos al sobreajuste.  
- Limitar la complejidad con hiperpar√°metros mejora la generalizaci√≥n.  
- Random Forest supera en desempe√±o y estabilidad al reducir la varianza mediante ensamble.  
- Las variables m√°s relevantes (flavonoides, alcohol) coinciden con factores enol√≥gicos reales.

---

## ‚úÖ Conclusiones
- Random Forest super√≥ consistentemente al √Årbol de Decisi√≥n, logrando desempe√±o perfecto en prueba.  
- Los hiperpar√°metros m√°s influyentes fueron `max_depth`, `min_samples_split` y `n_estimators`.  
- El an√°lisis de importancia de caracter√≠sticas fue coherente con el dominio, validando la utilidad del modelo.  

---

## üìå Recomendaciones
- Usar Random Forest como modelo base en problemas de clasificaci√≥n multiclase.  
- Limitar la profundidad de √°rboles cuando se priorice interpretabilidad y rapidez.  
- Optimizar hiperpar√°metros con Grid Search para mejorar robustez.  
- Replicar el an√°lisis en datasets de ingenier√≠a civil e infraestructura (ej. Smart Cities).  

---

## üìö Referencias
- Pedregosa, F. et al. (2011). *Scikit-learn: Machine Learning in Python*. Journal of Machine Learning Research, 12, 2825-2830.  
- Aeberhard, S., Forina, M. (1991). *Wine Recognition Data*. UCI Machine Learning Repository. Disponible en: [https://archive.ics.uci.edu/ml/datasets/wine](https://archive.ics.uci.edu/ml/datasets/wine)  
